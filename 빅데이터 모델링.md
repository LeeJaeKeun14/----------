# 빅데이터 모델링

- [빅데이터 모델링](#빅데이터-모델링)
  - [분석 모형 설계](#분석-모형-설계)
    - [분석 절차 수립](#분석-절차-수립)
      - [분석 모형 선정 필요성](#분석-모형-선정-필요성)
      - [분석 모형 정의](#분석-모형-정의)
      - [분석 모형 구축 절차](#분석-모형-구축-절차)
    - [분석 환경 구축](#분석-환경-구축)
      - [분석도구 선정](#분석도구-선정)
      - [데이터 분할](#데이터-분할)
  - [분석기법 적용](#분석기법-적용)
    - [분석기법](#분석기법)
      - [분석기법 개요](#분석기법-개요)
      - [회귀분석](#회귀분석)
      - [의사결정 나무](#의사결정-나무)
      - [인공신경망](#인공신경망)
      - [서포트벡터머신](#서포트벡터머신)
      - [연관성분석](#연관성분석)
      - [군집분석](#군집분석)
    - [고급 분석기법](#고급-분석기법)
      - [범주형 자료분석](#범주형-자료분석)
      - [다변량분성](#다변량분성)
      - [시계열분석](#시계열분석)
      - [베이즈 기법](#베이즈-기법)
      - [딥러닝 분석](#딥러닝-분석)
      - [비정형 데이터 분석](#비정형-데이터-분석)
      - [앙상블 분석](#앙상블-분석)
      - [비모수 통계](#비모수-통계)

## 분석 모형 설계

### 분석 절차 수립

#### 분석 모형 선정 필요성

- 분석 모형 선정 필요성
  - 분석 기법 또는 분석 알고리즘을 적용하기 전에 분석 모형에 대한 선정 필요
  - 붐석목적
    - 의사결정
    - 불확실성 해소
    - 요약
    - 인과관계 파악
    - 예측
  - 목적
    - 과거 데이터를 토대로 원인에 대해 분석하고 그 결과로 미래 예측
- 분석 모형 선정 프로세스
  - 문제요건 정의 또는 비즈니스 이해에 따른 대상 데이터 선정과 분석 목표 정의
  - 데이터 수집, 정리 및 도식화
  - 데이터 전처리
  - 최적의 분석 모형 선정

#### 분석 모형 정의

- 분석 모형 정의와 종류
  - 예측 분석 모형 : '어떤 일들이 발생할 것인가'
  - 현황 진단 모형 : '과거에 어떠한 상황이 왜 어떻게 일어났는가? 그리고 현재 어떠한 상태인가?
  - 최적화 분석 모형 : '어떻게 하면 원하는 결과가 일어날 수 있을까?'
- 분석 모형 정의를 위한 사전 고려사항
  - 분석을 진행하기 전에 분석이 실제 추진될 수 있을 지 가능성을 타진하는 것이 중요하다
    - 필요성
    - 파급효과
    - 추진 시급성
    - 구현 가능성
    - 데이터 수집 가능성
    - 모델 확장성
  - 상향식
  - 하향식

#### 분석 모형 구축 절차

- 분석 시나리오 작성
- 분석 모형 설계
  - 사전 확인 사항
  - 분석 모델링 설계와 검정
  - 분석 모델링에 적합한 알고리즘 설계
  - 분석 모형 개발 및 테스트
- 분석 모델링 설계와 검정
  - 유의수준 결정, 귀무가설과 대립가설 설정
  - 검정통계량의 설정
  - 기각역의 설정
  - 검정통계량 계산
  - 통계적인 의사결정(가설검정)
- 분석 모델링 설계와 검정 - 추정 방법에 대한 기술 검토

### 분석 환경 구축

#### 분석도구 선정

- R
  - 객체지향 언어
  - 고속메모리 처리
  - 다양한 자료 구조
  - 최신 패키지 제공
  - 시각화
  - 장점 :
    - 지속적으로 업데이트 되는 다양한 패키지
    - 그래프 및 도표 시각화 특화
  - 단점
    - 대용량 메모리 처리가 어려우며 보안 취약
    - 별도의 모듈 연동이 아니면 웹 브라우저에서 사용할 수 없음
  - R Studio
- Python
  - 배우기 쉬운 대화 기능의 인터프리터 언어
  - 동적인 데이터타입 결정 지원
  - 플랫폼 독립적 언어
  - 내장 객체 자료형과 자동 메모리 관리
  - 장점
    - 영어 문장 형식으로 빠른 개발 석도
    - 재사용 가능한 모듈 제공
    - C언어 포함 다른 언어 프로그램들과 연동성 높음
  - 단점
    - 컴파일 없이 인터프리터가 한 줄씩 실행하는 방식으로 실행속도가 느림
  - 파이썬 아나콘다

#### 데이터 분할

- 데이터 분할 정의
  - 학습 데이터
  - 평가 데이터
  - 검증 테스트 데이터
- 과대적합, 과소적합
  - 과대적합 : 학습 데이터에 대해서는 높은 정확도를 나타내지만 검증 데이터 예측하지 못함
  - K-fold 교차검증, 정규화 사용
- 과소적합
  - 모형이 단순하여 데이터 내부의 패턴 또는 규칙을 잘 학습하지 못하는 것
- 일반화
  - 학습 데이터를 통해 생성된 모델이 평가 데이터를 통한 성능 평가 외에도 검증용 테스트 데이터를 통해 정확하게 예측하는 모델을 알반화 모형이라 함

## 분석기법 적용

### 분석기법

#### 분석기법 개요

- 학습 유형에 따른 데이터 분석 모델
  - 지도학습
    - 분류 : 이진분류, 다중분류
    - 회귀
  - 비지도학습
    - 군집분석
    - 연관성분석
    - 인공신경망
    - 오토인코더
  - 준지도학습
    - GAN
    - 셀프트레이닝 : 정답이 있는 데이터로 모델을 학습한 뒤 정답이 없는 데이터를 예측. 이중 가장 확률이 높은 데이터들만 정답 데이터로 다시 가져가는 방식으로 학습
  - 강화학습
- 데이터분석 알고리즘 분야
  - 업리프트 모델링
  - 생존분석
  - 회귀분석
  - 시각화
  - 기초통계
  - 부스팅, 배깅
  - 시계열분석
  - 요인분석
  - 텍스트마이닝
  - 의사결정 나무, 랜덤포레스트
  - 신경 회로망
  - 군집분석
  - 추천 - 협업필터링
  - 앙상블 기법
  - 소셜네트워크 분석
  - 서포트벡터머신
  - 주성분분석

#### 회귀분석

- 독립변수로 종속변수를 예측하는 기법
  - 독립변수 : 입력값 또는 원인을 설명하는 변수
  - 종속변수 : 결과값 또는 효과를 설명하는 변수
  - 회귀계수 : 독립변수가 주어질 때의 종속변수의 기댓값, 최소제곱법 이용
  - 최소제곡법(최소자승법) : 잔차데곱의 합이 최소가 되게 하는 직선을 찾는 방법
- 선형회귀분석
  - 단순선형회귀분석 : 한개의 종속 변수 y와 한개의 독립변수 x
  - 다중선형회귀분석 : 독립변수 두 개 이상이고 종속변수가 y하나인 선형회귀분석
  - 가정
    - 선형성 : 독립변수와 종속변수가 선형
    - 잔차 정규성 : 잔차의 기댓값은 0, 정규분포
    - 잔차 독립성 : 잔차들은 서로 독립이여야 한다
    - 잔차 등분산성 : 잔차들의 분산이 일정해야 한다
    - 다중 공선성 : 상관관계로 인한 문제가 없어야 한다.
- 로지스틱 회귀분석
  - 종속변수가 연속형이 아닌 범주형을 예측
  - 단순 로지스틱 회귀분석
  - 다중 로지스틱 회귀분석
  - 모수에 대하여 비선형식이며 승산(odds)으로 로짓변환을 통해 선형함수로 치환 가능
  - 승산은 임의의 사건 A가 발생하지 않을 확률 대비 일어날 확률의 비율
- 장단점
  - 장점 : 크기와 관계없이 계수들에 대한 명료한 해석과 손시운 통계적 유의성 검증 가능
  - 단점 : 선형적인 관례로 데이터가 구성되어 있어야 사용 가능

#### 의사결정 나무

- 의사결정나무의 구성
  - 뿌리 마디
  - 중간 마디
  - 끝 마디
  - 자식 마디
  - 부모 마디
  - 가지
  - 깊이
- 의사결정나무의 종류
  - 분류나무
    - 카이제곱 통계량의 p, 지니계수, 엔트로피 지수
    - 불순도가 감소되는 방향으로 설정
  - 회귀나무
    - F-통계량 p, 분산의 감소량
    - 분산분석 F-통계량 p-값 : 등분산성을 검정하여 p-값이 커지면 등분산성이 있음을 뜻하므로 낮은 이질성, 순수도가 높아진다
    - 분산의 감소량 : 분산의 감소량이 최대화가 될수록 낮은 이질성, 순수도 증가
- 의사결정나무의 분석 과정
  - 변수 선택
  - 의사결정나무 형성
  - 가지치기
  - 모형 평가 및 예측 : 이익, 위험, 비용 등을 고려
    - 정보 획득
      - 순도가 증가하고 불확실성이 감소하는 것
    - 재귀적 분기 학습
  - 가지치기
    - 에러감소 가지치기
    - 룰 포스트 가지치기
  - 타당성 평가
  - 해석 및 예측
- 의사결정나무의 대표적 알고리즘
  | | 범주형/이산형 목표변수 | 연속형 목표변수 |
  | :---: | :---: | :---: |
  | CART       | 카이제곱 통계량 | ANOVA F-통계량 |
  | C4.5, C5.0 | 지니 지수 | 분산감소량 |
  | CHAIK      | 엔트로피지수 | |
- 랜덤 포레스트
  - 부트스트래핑
  - 배깅
  - 부스팅
- 의사결정나무의 장단점
  - 장점
    - 연속형, 범주형 변수 모두 적용, 변수 비교가 가능하며 규칙에 대해 이해하기 쉽다
    - 데이터로부터 규칙을 도출하는 데에 유용하므로 DB 마케팅, CBM, 시장조사, 기업 부도/환율 예측 등 다양한 분야에 활용한다
  - 단점
    - 트리구조가 복잡할 시 예측 / 해석력이 떨어진다
    - 데이터 변형에 민감하다.

#### 인공신경망

- 인공신경망의 특징
  - 신경세포인 뉴런을 기본으로 한 기계학습 기법
  - 범주형 변수
    - 일정 빈도 이상의 값으로 비슷하고 범주가 일정한 구간이어야 한다
  - 연속형 변수
    - 입력변수 값들이 범위가 큰 차이가 없어 표준화가 가능한 경우에 더 적합하다.
- 인공신경망의 발전
  - 기존 신경망 다층 퍼셉트론이 가진 문제
    - 사라지는 경사도
    - 과대적합
  - 딥러닝의 등장
    - 경사도 문제 해결
    - 오버피팅 방지하는 초기화
    - 알고리즘의 발전 및 고의로 데이터 누락시키는 드롭아웃
  - GPU 발전
  - DNN : CNN, RNN, LSTM, GRU, GAN
- 인공신경망의 원리
  - 지도학습
  - 비지도학습
  - 강화학습
  - 뉴런 간의 연결 방법
    - 층간 연결 : 서로 다른 층에 존재하는 뉴런과 연결
    - 층내 연결 : 동일 층 내의 뉴런과의 연결
    - 순환 연결 : 어떠한 뉴런의 출력이 자기 자신에게 입력되는 연결
- 학습
  - 손실함수 : 신경망이 출력한 값과 실제 값과의 오차에 대한 함수이다
  - 평균제곱 오차 : MSE
    $$ E = \frac{1}{n} \sum_k (y_k - t_k)^2 $$
  - 교차엔트로피 오차
    $$ E = -\sum_kt_k \log y_k $$
- 학습 알고리즘
  - 1단계 : 미니배치
    - 훈련 데이터 중 일부를 무작위로 선택한 데이터를 미니배치라고 하며 이에 대한 손실함수를 줄이는 것으로 목표를 설정한다
  - 2단계 : 기울기 산출
    - 미니배치의 손실함수 값을 최소화하기 이해 경사법으로 가중치 매개변수의 기울기를 일반적으로 미분을 통해 구한다.
  - 3단계 : 매개변수 갱신
    - 가중치 매개변수를 기울기 방향으로 조금씩 업데이트 하면서 1~3단계를 반복한다
- 오차역전파
  - 가중치 매개변수 기울기를 미분을 통해 진행하는 것은 시간 소모가 크므로 오차를 출력층에서 입력층으로 전달, 연쇄법칙을 활용한 역전파를 통해 가중치를 편향을 계산.
  - 활성화 함수
    - 렐루
    - 시그모이드
    - 아핀
    - 소프트맥스
- 활성화 함수
- 과대적합
  - 해결방안
    - 가중치 매개변수 절대값을 가능한 적게 만드는 가중치 감소
    - 일정 비율 뉴런만 학습하는 드롭아웃
    - 릿지 : L2 규제(정규화)
- 딥러닝 모델 종류
  - CNN
    - 신경네트워크의 한 종류, 인접하는 계층의 모든 뉴런과 결합된 완전 연결을 구현한 아핀 계층을 사용하여 모든 입력 데이터들을 동등한 뉴런으로 처리
      - 형상정보를 처리할 수 없었던 과거 모델들과 달리 이미지 형상을 유지할 수 있는 모델로 데이터 특징, 차원을 추출하여 패턴을 이해하는 방식으로 이미지 추출, 클래스 분류
      - CNN에서 특징을 추출하는 과정은 합성곱 계층과 풀링 계층으로 나눠지는데 입력된 데이터를 필터가 순회하며 합성곱을 계산한 뒤 특징지도 생성
    - 특징 지도는 서브샘플링을 통해 차원을 줄여주는 효과를 지니며 필터 크기, 스프라이드, 패딩 적용여부, 최대 풀링 크기에 따라 풀력 데이터의 구조가 결정된다
    - 합성곱 계층
      - 패딩 :
        - 합성곱 연산을 반복수행 시 출력크기가 1이 되어 더이상 연산을 진행하기 어려운 상태를 사전 예방하기 위한 조치, 출력크기 제한
        - 연산 전 입력 데이터 주위를 0 또는 1로 채워 출력 데이터의 크기를 동일하게 설정
      - 스프라디으
        - 필터를 적용하는 위치간격을 위믜
        - 스프라이드가 커지면 필터의 윈도우가 적용되는 간격이 넓어져 출력 데이터 크기가 줄어듬
      - 풀링 계층
        - 선택적 요소이며 독립적인 채널별 연산. 입력데이터의 채넔구가 변화되지 않도록 2차원 데이터의 새로 및 가로방향의 공간을 줄이는 연산
  - RNN
    - 순서를 가진 데이터를 입력하여 단위 간 연결이 시퀸스를 따라 방향성 그래프를 형성하는 신경네트워크 모델로 내부 상태를 이용하여 입력 시퀸스 처리
    - 중간층(은닉층)이 순환구조로 동일한 가중치를 공유한다.
    - 가중치 업데이트를 위해 과거시점까지 역전파하는 BPTT(Back Propagation Through Time)를 활용한다.
  - LSTM (Long Short Term Memory Network)
    - RNN은 점차 데이터가 소멸해 가는 문제를 해결하기 위한 모델
    - 입력게이트, 출력게이트 망각데이트 구조로 가중치를 곱한 후 활성화 함수를 거치지 않고 컨트롤 게이트를 통해 상황에 맞게 값을 조절함으로써 문제를 해결
  - 오토인코더
    - 비지도학습 모델, 다차원 데이터를 저차우너으로 바꾸고 바꾼 저차원 데이터를 고차원으로 바꾸며 특징점 찾아낸다
    - 디노이징 오토인코더
    - 최소 오토인코더
    - VAE
  - GAN
    - 학습데이터 패턴과 유사하게 만드는 생성자, 네트워크와 패턴의 진위여부를 판별하는 판별자로 구분
    - 판별자 네트워크 : 랜덤 노이즈 m개를 재생성하여 생성자가 판벌자의 정확도를 최소화하도록 학습
    - 생성자 네트워크에 랜덤 노이즈가 주어지며 출력은 학습 데이터와 유사한 패턴으로 변화하는 함수를 학습
  - 인공신경망의 장단점
    - 장점
      - 비선형적 예측 가능
      - 다양한 데이터를 유형, 새로운 학습 환경, 불완전한 데이터 입력 등 적용가능
    - 단점
      - 데이터가 커질수록 학습시키는 데에 시간 비용이 기하급수적으로 커질 수 있다.

#### 서포트벡터머신

- SVM의 주요 요소
  - 벡터
  - 결정역역
  - 초평면
  - 서포트벡터
  - 마진
- SVM의 핵심적 특징
  - 여백(마진)의 최대화로 일반화 능력의 극대화
  - 초평면의 마진은 각 서포트 벡터를 지나는 초평면 사이의 거리를 의미
- 장단점
  - 장점
    - 다양한 라이브러리로 사용하기 쉬우며 분류, 회귀 예측 문제에 동시에 활용 가능
    - 신경망 기법에 비해 적은 데이터로 학습이 간으하며 과대적합, 과소적합 정도가 덜하다
  - 단점
    - 이진분류만 가능하며 데이터가 많은 시 모델 학습 시간이 오래 소요도니다
    - 가각 분류에 대한 모델 구축이 필요하다

#### 연관성분석

- 연관성분석
  - 둘 이상의 거래, 사전에 포함된 항목들의 관련성을 파악하는 탐색적 데이터 분석 기법
- 순서
  - 데이터 간 규칙 생성
  - 어떠한 규칙이 데이터에 특성에 부합되는지 기준 설정
    - 지지도
    - 신뢰도
    - 향상도
  - 규칙의 효용성 평가
- 아프리오리 알고리즘
- 연관성분석의 장단점
  - 장점 : 분석 결과가 이해하기 쉽고 실제 적용하기에 용이하다
  - 단점
    - 품목이 많아질수록 연관성 규칙이 더 많이 발견되나 의미성에 대해 사전 판단이 필요
    - 상당 수의 계산 과정이 필요

#### 군집분석

- 군집분류 시 기본적인 가정
  - 하나의 군집 내에 속한 개체들의 특징은 동일하다
- 군집분석의 척도
  - 거리는 값이 작을수록 두 관찰치가 유사함
  - 유사성은 값이 클수록 두 관찰치가 서로 유사함
  - 거리
    - 유클리드 거리
    - 맨허탄 거리 : 블록별로 택시가 지나가 듯이 출발점과 도착점을 잇는 가장 짧은 거리
    - 민코우스키 거리 : m=1일 때 맨하탄 거리와 같고 m=2 일때 유클리드 거리와 같다.
    - 마할라노비스 거리
    - 자카드 거리 : 비교 대상인 두 개의 객체를 특징즐의 결헙으로 간주하여 범주형 데이터에서 비유사성을 측정하는 지표
- 군집분석의 종류
  - 계층적 군집분석
    - 최단 연결법
    - 최장 연결법
    - Ward 연결법
  - 비계층적 군집분석
    - K-평균
    - 밀도비간 클러스터링 (DBSCAN)
    - 확률 분포 기반 클러스터링
- 군집분포의 장단점
  - 장점
    - 다양한 데이터 형태에 적용이 가능하다
    - 특징 변수에 대한 정의가 필요하지 않는 적용이 용이한 탐색적 기법이다
  - 단점
    - 초기 군집 수, 관측시간의 거리 등의 결정에 따라 결과가 바뀔 수 있다
    - 사전 주어진 목표가 없으므로 결과 해석이 어렵다.

### 고급 분석기법

#### 범주형 자료분석

- 범주형 자료분석의 통계적 정의
  - 변수들이 이산형 변수일 때 주로 사용하는 분석
- 자료의 분석
  
  | 독립변수 | 종속변수 | 분석방법 | 예제 |
  | :---: | :---: | :---: | :---: |
  | 범주형 | 범주형 | 빈도분석, 카이제곱검정, 로그선형모형 | 지역별 선호정당 |
  | 연속형 | 범주형 | 로지스틱 회귀분석 | 소득에 따른 결혼의 선호도 |
  | 범주형 | 연속형 | T검정(2그룹), 분산분석(2그룹이상) | 지역별 가계수입의 차이 |
  | 연속형 | 연속형 | 상관분석, 회귀분석 | |

  - 분할표
    - 차원
    - 수준
    - 비율의 차이
    - 상대적 위험도
    - 오즈비
  - 빈도분석
    - 빈도분석은 질적자료를 대상으로 빈도와 비율을 곗나한 때 쓰인다
  - 교차분석 또는 카이제곱검정
    - 두 범주형 변수가 서로 상관이 있는지 독립인지를 판단하는 통계적 검정방법
  - 로지스틱 회귀분석
  - t검정
  - 분산분석

#### 다변량분성

- 용어
  - 종속 기법
  - 상호의존적 기법
  - 명목 척도
  - 순위 척도
  - 동간 척도
  - 비율 척도
  - 정량적 자료
  - 비정량적 자료
  - 변량
- 다변량분석기법의 분류
  - 다중회귀분석
  - 다변량분산분석, 다변량공분산분석
    - ANOVA
    - ANCOVA
  - 정준상관분석
  - 요인분석
  - 군집분석
  - 다중판별분석
  - 다차원척도법

#### 시계열분석

- 시계열 자료
  - 이산 시계열
  - 연속 시계열
  - 시차
- 시계열자료의 성분
  - 불규칙 성분
  - 체계적 성분
    - 추세성분
    - 계절성분
    - 순환성분
    - 복합성분
    - 자기상관성
    - 백색잡음
- 정상성 : 시계열 데이터가 평균과 분산인 일정한 경우
  - 평균이 일정
  - 분산이 일정
  - 공분산의 경우도 단지 시차에만 의종하며 특정시점에는 의존하지 않음
  - 정상성을 가ㅈ는 시계열 자료의 특징
- 시계열자료의 분석 방법
  - 예측목적
    - 단순방법
      - 추세분석 이동평균
      - 평활법
      - 분해법
    - 모형기반
      - 자기회귀모형
      - 자기회귀이동평균모형 ARMA
      - 자기회귀누적이동평균모형 ARIMA
  - 이해와 제어의 목적
    - 스펙트럼분석
    - 개입분석
  - 단순방법
    - 이동평균법 MA
      $$ MA(x, n) = \frac{1}{n}(x_k + x_{k-1} + \dots + x_{k-n+1}) = \frac{1}{n}\sum^n_{i=k-n+1}x_i $$
      - 여기서 n은 관찰기간(윈도우) $x_k$는 가장 최근 시점의 관찰값
      - 다양한 방법으로 추세의 판단이 가능하다
    - 지수평활법
      $$ Z_{n+1} = \lambda x_n + (1-\lambda)Z_n $$
      - 지수평활법은 단기간에 발생하는 불규칙 변동을 평활하는데 주로 사용
      - 지수평활계수의 효과로 과거 데이터일수록 가중치를 적게 해당
    - 분해법
      - 시계열자료의 성분 분류대로 시계열 데이터를 분해
      - 계절적, 추세/순환 성분 분리
  - 모형에 의한 방법
    - 자기회귀모형 AR
      - 과거의 패턴이 지속된다면 시계열 데이터 관측치 $X_i$는 과거 관측치에 의해 예측할 수 있을 것이다
        $$ AR(p) : X_t = \alpha_tX_{t-1} + \dots + \alpha_pX_{t-p} + \epsilon_t $$
        - 여기서 백색잡음은 오차항을 의미 $\epsilon_t \sim iid N(0, \sigma^2)$
    - 자기회귀이동모형 ARMA
      - 시계열 데이터 관측치 $X_i$가 과거 관측치들과 과거오차들에 의해서 설명되어질 때
        $$ AR(p) : X_t = \alpha_tX_{t-1} + \dots + \alpha_pX_{t-p} + \epsilon_t $$
        $$ MA(q) : X_t = \epsilon_t - \beta_1\epsilon_{t-1} - \dots - \beta_p\epsilon_{t-q}$$
        $$ ARMA(p, q) : X_t = \alpha_tX_{t-1} + \dots + \alpha_pX_{t-p} - \beta_1\epsilon_{t-1} - \dots - \beta_p\epsilon_{t-q} $$
    - 자기회귀누적이동평균모형
      - 비정상성을 가지는 시계열 데이터 분석에 활용
      - ARIMA(p,d,q)
        - d=0 : ARMA(p,q) 정상성을 가지는 데이ㅓ
        - p=0 : IMA(d, q) 이므로 d번 차분하면 MA(q) 모형을 따른다
        - q=0 : ARI(p,d) 이므로 d번 차분하면 AR(p) 모형을 따른다

#### 베이즈 기법

- 베이즈 추론
  - 통계적 추론의 한 방법으로 추론 대상의 사전 확률과 추가적인 정보를 통해 해당 대상의 사후 확률을 추론하는 방법이다.
  - 확률론적 의미해석
    $$ P(B|A) = \frac{P(A\cap B)}{P(A)} $$
    , 단 P(A) >0
    - 이고 여기서 사후확률은
    $$ P(A|B) = \frac{A(\cap B)}{P(B)} = \frac{P(B|A)P(A)}{P(B)} $$
  - 베이즈 기법의 개념
    - 객관적 관점으로 베이즈 통계법칙은 이성적, 보편적으로 증명될 수 있으며 논리의 확장으로 설명될 수 있다. 주관주의 확률 이론의 관점으로 보면 지식의 상태는 개인적인 믿음의 정도로 측정할 수 있다.
- 베이즈 기법 적용
  - 회귀분석모델에서 베이즈 기법의 적용
    - 선형회귀분석 모델
      - 추정과 실제의 차이를 최소화하는 것
    - 기존 머신러닝의 방법
      - 머신러닝은 경사하강법과 같은 알고리즘을 통해 점진적으로 학습하여 매개변수를 찾아간다.
    - 베이지안 확률론의 적용개념
      - 추정하고자 하는 $\theta_0, \theta_1$이 하나의 특정한 값을 갖는 것이 아니라 분포를 갖는다.
    - 분류에서 베이즈 기법의 적용
      - 나이브 베이즈 분류
      - 이벤트 모델
        - 가우시간 나이브 베이즈
        - 다항분포 나이브 베이즈
        - 베르누이 나이브 베이즈

#### 딥러닝 분석

- 딥러닝 분석의 개념
  - 인공신경망
    - 단점
      - 계산속도의 저하
      - 초기치의 의존성
      - 과적합 문제
  - 딥러닝
    - 노드
    - 가중치
    - 활성화함수
- 딥러닝 분석 알고리즘
  - 심층 신경망 DNN
    - 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공 신경망
  - 합성곱 신경망 CNN
    - 파생 알고리즘
      - 합성곱 심층 신뢰 신경망 CDBN
        - CNN과 심층 신뢰 신경망의 결합
  - 순환 신경망 RNN
    - 파생 알고리즘
      - 완전순환망
      - Hopfield Network
      - ESN
      - LSTM
      - Bi directional RNN
      - CTRNN
      - Hierarchical RNN
      - Second order RNN
  - 심츰 신뢰 신경망 DBN
    - 기계학습에서 사용되는 그래프 생성 모형이다.
    - 선행학습을 통해 초기 가중치를 학습한 후 역전파 혹은 다른 판별 알고리즘을 통해 가중치의 미조정을 할 수 있다.
      - 이러한 특성은 훈련용 데이터가 적을 때 괸장히 유용하다.

#### 비정형 데이터 분석

- 비정형 데이터
  - 데이터 세트가 아닌 하나의 데이터가 수집 데이터로 객체화 되어 있다.
  - 데이터 수집 난이도
    - 정형 : 하
    - 비정형 : 상
  - 데이터 처리 아키텍처
    - 정형 : 일반적인 구조
    - 반정형 : 데이터 메타구조를 해석해 정형 데이터로 수정
    - 비정형 : 텍스트나 파일을 파싱해 메타구조형태로 바꾸고 이를 정형으로 수정
  - 데이터의 잠재적 가치
    - 정형 : 하
    - 비정형 : 상
- 비정형 데이터 분석
  - 비정형 데이터의 분석의 기본 원리
    - 비정형 데이터의 내용 파악과 비정형 데이터 속 패턴 발견을 위해 데이터 마이닝, 텍스트 분석, 비표준 텍스트 분석 등과 같은 기법 사용
  - 데이터 마이닝
    - 대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 패턴을 분석하여 가치있는 정보를 추출하는 과정
    - 적용분야
      - 분류
      - 군집화
      - 연관성
      - 연속성
      - 에측
  - 텍스트 마이닝
    - 자연어처리
  - 웹 마이닝
  - 오피니언 마이닝
  - 리얼리티 마이닝

#### 앙상블 분석

- 앙상블 분석 정의
  - 주어진 자료로부터 어려 개의 학습 모형을 만든 후 학습 모형들을 조합하여 하나의 최종 모형을 만드는 개념이다
  - 악학습기 : 무작위 선정이 아닌 성공확률이 높은 학습규칙을 말한다
  - 강학습기 : 약학습기로부터 만들어내는 강력한 학습 규칙
- 앙상블 분석의 이해
  - 다양한 약학습기를 통해 강학습기를 만들어가는 과정이다
- 앙상블 분석의 종류
  - 보팅 : 투표
  - 부스팅
    - 가중치를 활용하여 연속적인 약학습기를 생성하고 이를 통해 강학습기를 만드는 방법
  - 배깅
    - 샘플을 여러 번 뽑아(bootstrap) 각 모델을 학습시켜 결과물을 집계

#### 비모수 통계

- 모수의 정의
  - 모수는 수학과 통계학에서 어떠한 시스템이나 함수의 특정한 성질을 나타내는 변수를 말한다
- 비모수 통계의 개념
  - 비모수 통계는 통계학에서 모수에 대한 가정을 전제로 하지 않고 모집단의 형태에 관계없이 주어진 데이터에서 직접 확률을 계산하는 통계학적 검정을 하는 분석이다
- 비모수 통계법의 사용조건
  - 자료가 나타나는 모집단의 형상이 정규분포가 아닐때
  - 자료가 나타내는 현상이 정규분포로 적적히 변환되지 못할 때
  - 자료의 표본이 적을 때
  - 자료들이 서로 독립적일 때
  - 변인의 척도가 명명척도나 서열척도일 때
- 비모수 통계의 특징
  - 가정을 만족시키지 못한 상태에서 그대로 모수 통계분석을 함으로써 발생할 수 있는 오를 줄일 수 있다.
- 비모수적 통계 검정법
  - 부호검정
  - 윌콕슨 부호순위 검정
  - 만 위트니 검정
  - 크루스칼 왈라스 검정

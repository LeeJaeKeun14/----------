# 빅데이터 모델링

- [빅데이터 모델링](#빅데이터-모델링)
  - [분석 모형 설계](#분석-모형-설계)
    - [분석 절차 수립](#분석-절차-수립)
      - [분석 모형 선정 필요성](#분석-모형-선정-필요성)
      - [분석 모형 정의](#분석-모형-정의)
      - [분석 모형 구축 절차](#분석-모형-구축-절차)
    - [분석 환경 구축](#분석-환경-구축)
      - [분석도구 선정](#분석도구-선정)
      - [데이터 분할](#데이터-분할)
  - [분석기법 적용](#분석기법-적용)
    - [분석기법](#분석기법)
      - [분석기법 개요](#분석기법-개요)
      - [회귀분석](#회귀분석)
      - [의사결정 나무](#의사결정-나무)
      - [인공신경망](#인공신경망)
      - [서포트벡터머신](#서포트벡터머신)
      - [연관성분석](#연관성분석)
      - [군집분석](#군집분석)

## 분석 모형 설계

### 분석 절차 수립

#### 분석 모형 선정 필요성

- 분석 모형 선정 필요성
  - 분석 기법 또는 분석 알고리즘을 적용하기 전에 분석 모형에 대한 선정 필요
  - 붐석목적
    - 의사결정
    - 불확실성 해소
    - 요약
    - 인과관계 파악
    - 예측
  - 목적
    - 과거 데이터를 토대로 원인에 대해 분석하고 그 결과로 미래 예측
- 분석 모형 선정 프로세스
  - 문제요건 정의 또는 비즈니스 이해에 따른 대상 데이터 선정과 분석 목표 정의
  - 데이터 수집, 정리 및 도식화
  - 데이터 전처리
  - 최적의 분석 모형 선정

#### 분석 모형 정의

- 분석 모형 정의와 종류
  - 예측 분석 모형 : '어떤 일들이 발생할 것인가'
  - 현황 진단 모형 : '과거에 어떠한 상황이 왜 어떻게 일어났는가? 그리고 현재 어떠한 상태인가?
  - 최적화 분석 모형 : '어떻게 하면 원하는 결과가 일어날 수 있을까?'
- 분석 모형 정의를 위한 사전 고려사항
  - 분석을 진행하기 전에 분석이 실제 추진될 수 있을 지 가능성을 타진하는 것이 중요하다
    - 필요성
    - 파급효과
    - 추진 시급성
    - 구현 가능성
    - 데이터 수집 가능성
    - 모델 확장성
  - 상향식
  - 하향식

#### 분석 모형 구축 절차

- 분석 시나리오 작성
- 분석 모형 설계
  - 사전 확인 사항
  - 분석 모델링 설계와 검정
  - 분석 모델링에 적합한 알고리즘 설계
  - 분석 모형 개발 및 테스트
- 분석 모델링 설계와 검정
  - 유의수준 결정, 귀무가설과 대립가설 설정
  - 검정통계량의 설정
  - 기각역의 설정
  - 검정통계량 계산
  - 통계적인 의사결정(가설검정)
- 분석 모델링 설계와 검정 - 추정 방법에 대한 기술 검토

### 분석 환경 구축

#### 분석도구 선정

- R
  - 객체지향 언어
  - 고속메모리 처리
  - 다양한 자료 구조
  - 최신 패키지 제공
  - 시각화
  - 장점 :
    - 지속적으로 업데이트 되는 다양한 패키지
    - 그래프 및 도표 시각화 특화
  - 단점
    - 대용량 메모리 처리가 어려우며 보안 취약
    - 별도의 모듈 연동이 아니면 웹 브라우저에서 사용할 수 없음
  - R Studio
- Python
  - 배우기 쉬운 대화 기능의 인터프리터 언어
  - 동적인 데이터타입 결정 지원
  - 플랫폼 독립적 언어
  - 내장 객체 자료형과 자동 메모리 관리
  - 장점
    - 영어 문장 형식으로 빠른 개발 석도
    - 재사용 가능한 모듈 제공
    - C언어 포함 다른 언어 프로그램들과 연동성 높음
  - 단점
    - 컴파일 없이 인터프리터가 한 줄씩 실행하는 방식으로 실행속도가 느림
  - 파이썬 아나콘다

#### 데이터 분할

- 데이터 분할 정의
  - 학습 데이터
  - 평가 데이터
  - 검증 테스트 데이터
- 과대적합, 과소적합
  - 과대적합 : 학습 데이터에 대해서는 높은 정확도를 나타내지만 검증 데이터 예측하지 못함
  - K-fold 교차검증, 정규화 사용
- 과소적합
  - 모형이 단순하여 데이터 내부의 패턴 또는 규칙을 잘 학습하지 못하는 것
- 일반화
  - 학습 데이터를 통해 생성된 모델이 평가 데이터를 통한 성능 평가 외에도 검증용 테스트 데이터를 통해 정확하게 예측하는 모델을 알반화 모형이라 함

## 분석기법 적용

### 분석기법

#### 분석기법 개요

- 학습 유형에 따른 데이터 분석 모델
  - 지도학습
    - 분류 : 이진분류, 다중분류
    - 회귀
  - 비지도학습
    - 군집분석
    - 연관성분석
    - 인공신경망
    - 오토인코더
  - 준지도학습
    - GAN
    - 셀프트레이닝 : 정답이 있는 데이터로 모델을 학습한 뒤 정답이 없는 데이터를 예측. 이중 가장 확률이 높은 데이터들만 정답 데이터로 다시 가져가는 방식으로 학습
  - 강화학습
- 데이터분석 알고리즘 분야
  - 업리프트 모델링
  - 생존분석
  - 회귀분석
  - 시각화
  - 기초통계
  - 부스팅, 배깅
  - 시계열분석
  - 요인분석
  - 텍스트마이닝
  - 의사결정 나무, 랜덤포레스트
  - 신경 회로망
  - 군집분석
  - 추천 - 협업필터링
  - 앙상블 기법
  - 소셜네트워크 분석
  - 서포트벡터머신
  - 주성분분석

#### 회귀분석

- 독립변수로 종속변수를 예측하는 기법
  - 독립변수 : 입력값 또는 원인을 설명하는 변수
  - 종속변수 : 결과값 또는 효과를 설명하는 변수
  - 회귀계수 : 독립변수가 주어질 때의 종속변수의 기댓값, 최소제곱법 이용
  - 최소제곡법(최소자승법) : 잔차데곱의 합이 최소가 되게 하는 직선을 찾는 방법
- 선형회귀분석
  - 단순선형회귀분석 : 한개의 종속 변수 y와 한개의 독립변수 x
  - 다중선형회귀분석 : 독립변수 두 개 이상이고 종속변수가 y하나인 선형회귀분석
  - 가정
    - 선형성 : 독립변수와 종속변수가 선형
    - 잔차 정규성 : 잔차의 기댓값은 0, 정규분포
    - 잔차 독립성 : 잔차들은 서로 독립이여야 한다
    - 잔차 등분산성 : 잔차들의 분산이 일정해야 한다
    - 다중 공선성 : 상관관계로 인한 문제가 없어야 한다.
- 로지스틱 회귀분석
  - 종속변수가 연속형이 아닌 범주형을 예측
  - 단순 로지스틱 회귀분석
  - 다중 로지스틱 회귀분석
  - 모수에 대하여 비선형식이며 승산(odds)으로 로짓변환을 통해 선형함수로 치환 가능
  - 승산은 임의의 사건 A가 발생하지 않을 확률 대비 일어날 확률의 비율
- 장단점
  - 장점 : 크기와 관계없이 계수들에 대한 명료한 해석과 손시운 통계적 유의성 검증 가능
  - 단점 : 선형적인 관례로 데이터가 구성되어 있어야 사용 가능

#### 의사결정 나무

- 의사결정나무의 구성
  - 뿌리 마디
  - 중간 마디
  - 끝 마디
  - 자식 마디
  - 부모 마디
  - 가지
  - 깊이
- 의사결정나무의 종류
  - 분류나무
    - 카이제곱 통계량의 p, 지니계수, 엔트로피 지수
    - 불순도가 감소되는 방향으로 설정
  - 회귀나무
    - F-통계량 p, 분산의 감소량
    - 분산분석 F-통계량 p-값 : 등분산성을 검정하여 p-값이 커지면 등분산성이 있음을 뜻하므로 낮은 이질성, 순수도가 높아진다
    - 분산의 감소량 : 분산의 감소량이 최대화가 될수록 낮은 이질성, 순수도 증가
- 의사결정나무의 분석 과정
  - 변수 선택
  - 의사결정나무 형성
  - 가지치기
  - 모형 평가 및 예측 : 이익, 위험, 비용 등을 고려
    - 정보 획득
      - 순도가 증가하고 불확실성이 감소하는 것
    - 재귀적 분기 학습
  - 가지치기
    - 에러감소 가지치기
    - 룰 포스트 가지치기
  - 타당성 평가
  - 해석 및 예측
- 의사결정나무의 대표적 알고리즘
  | | 범주형/이산형 목표변수 | 연속형 목표변수 |
  | :---: | :---: | :---: |
  | CART       | 카이제곱 통계량 | ANOVA F-통계량 |
  | C4.5, C5.0 | 지니 지수 | 분산감소량 |
  | CHAIK      | 엔트로피지수 | |
- 랜덤 포레스트
  - 부트스트래핑
  - 배깅
  - 부스팅
- 의사결정나무의 장단점
  - 장점
    - 연속형, 범주형 변수 모두 적용, 변수 비교가 가능하며 규칙에 대해 이해하기 쉽다
    - 데이터로부터 규칙을 도출하는 데에 유용하므로 DB 마케팅, CBM, 시장조사, 기업 부도/환율 예측 등 다양한 분야에 활용한다
  - 단점
    - 트리구조가 복잡할 시 예측 / 해석력이 떨어진다
    - 데이터 변형에 민감하다.

#### 인공신경망

- 인공신경망의 특징
  - 신경세포인 뉴런을 기본으로 한 기계학습 기법
  - 범주형 변수
    - 일정 빈도 이상의 값으로 비슷하고 범주가 일정한 구간이어야 한다
  - 연속형 변수
    - 입력변수 값들이 범위가 큰 차이가 없어 표준화가 가능한 경우에 더 적합하다.
- 인공신경망의 발전
  - 기존 신경망 다층 퍼셉트론이 가진 문제
    - 사라지는 경사도
    - 과대적합
  - 딥러닝의 등장
    - 경사도 문제 해결
    - 오버피팅 방지하는 초기화
    - 알고리즘의 발전 및 고의로 데이터 누락시키는 드롭아웃
  - GPU 발전
  - DNN : CNN, RNN, LSTM, GRU, GAN
- 인공신경망의 원리
  - 지도학습
  - 비지도학습
  - 강화학습
  - 뉴런 간의 연결 방법
    - 층간 연결 : 서로 다른 층에 존재하는 뉴런과 연결
    - 층내 연결 : 동일 층 내의 뉴런과의 연결
    - 순환 연결 : 어떠한 뉴런의 출력이 자기 자신에게 입력되는 연결
- 학습
  - 손실함수 : 신경망이 출력한 값과 실제 값과의 오차에 대한 함수이다
  - 평균제곱 오차 : MSE
    $$ E = \frac{1}{n} \sum_k (y_k - t_k)^2 $$
  - 교차엔트로피 오차
    $$ E = -\sum_kt_k \log y_k $$
- 학습 알고리즘
  - 1단계 : 미니배치
    - 훈련 데이터 중 일부를 무작위로 선택한 데이터를 미니배치라고 하며 이에 대한 손실함수를 줄이는 것으로 목표를 설정한다
  - 2단계 : 기울기 산출
    - 미니배치의 손실함수 값을 최소화하기 이해 경사법으로 가중치 매개변수의 기울기를 일반적으로 미분을 통해 구한다.
  - 3단계 : 매개변수 갱신
    - 가중치 매개변수를 기울기 방향으로 조금씩 업데이트 하면서 1~3단계를 반복한다
- 오차역전파
  - 가중치 매개변수 기울기를 미분을 통해 진행하는 것은 시간 소모가 크므로 오차를 출력층에서 입력층으로 전달, 연쇄법칙을 활용한 역전파를 통해 가중치를 편향을 계산.
  - 활성화 함수
    - 렐루
    - 시그모이드
    - 아핀
    - 소프트맥스
- 활성화 함수
- 과대적합
  - 해결방안
    - 가중치 매개변수 절대값을 가능한 적게 만드는 가중치 감소
    - 일정 비율 뉴런만 학습하는 드롭아웃
    - 릿지 : L2 규제(정규화)
- 딥러닝 모델 종류
  - CNN
    - 신경네트워크의 한 종류, 인접하는 계층의 모든 뉴런과 결합된 완전 연결을 구현한 아핀 계층을 사용하여 모든 입력 데이터들을 동등한 뉴런으로 처리
      - 형상정보를 처리할 수 없었던 과거 모델들과 달리 이미지 형상을 유지할 수 있는 모델로 데이터 특징, 차원을 추출하여 패턴을 이해하는 방식으로 이미지 추출, 클래스 분류
      - CNN에서 특징을 추출하는 과정은 합성곱 계층과 풀링 계층으로 나눠지는데 입력된 데이터를 필터가 순회하며 합성곱을 계산한 뒤 특징지도 생성
    - 특징 지도는 서브샘플링을 통해 차원을 줄여주는 효과를 지니며 필터 크기, 스프라이드, 패딩 적용여부, 최대 풀링 크기에 따라 풀력 데이터의 구조가 결정된다
    - 합성곱 계층
      - 패딩 :
        - 합성곱 연산을 반복수행 시 출력크기가 1이 되어 더이상 연산을 진행하기 어려운 상태를 사전 예방하기 위한 조치, 출력크기 제한
        - 연산 전 입력 데이터 주위를 0 또는 1로 채워 출력 데이터의 크기를 동일하게 설정
      - 스프라디으
        - 필터를 적용하는 위치간격을 위믜
        - 스프라이드가 커지면 필터의 윈도우가 적용되는 간격이 넓어져 출력 데이터 크기가 줄어듬
      - 풀링 계층
        - 선택적 요소이며 독립적인 채널별 연산. 입력데이터의 채넔구가 변화되지 않도록 2차원 데이터의 새로 및 가로방향의 공간을 줄이는 연산
  - RNN
    - 순서를 가진 데이터를 입력하여 단위 간 연결이 시퀸스를 따라 방향성 그래프를 형성하는 신경네트워크 모델로 내부 상태를 이용하여 입력 시퀸스 처리
    - 중간층(은닉층)이 순환구조로 동일한 가중치를 공유한다.
    - 가중치 업데이트를 위해 과거시점까지 역전파하는 BPTT(Back Propagation Through Time)를 활용한다.
  - LSTM (Long Short Term Memory Network)
    - RNN은 점차 데이터가 소멸해 가는 문제를 해결하기 위한 모델
    - 입력게이트, 출력게이트 망각데이트 구조로 가중치를 곱한 후 활성화 함수를 거치지 않고 컨트롤 게이트를 통해 상황에 맞게 값을 조절함으로써 문제를 해결
  - 오토인코더
    - 비지도학습 모델, 다차원 데이터를 저차우너으로 바꾸고 바꾼 저차원 데이터를 고차원으로 바꾸며 특징점 찾아낸다
    - 디노이징 오토인코더
    - 최소 오토인코더
    - VAE
  - GAN
    - 학습데이터 패턴과 유사하게 만드는 생성자, 네트워크와 패턴의 진위여부를 판별하는 판별자로 구분
    - 판별자 네트워크 : 랜덤 노이즈 m개를 재생성하여 생성자가 판벌자의 정확도를 최소화하도록 학습
    - 생성자 네트워크에 랜덤 노이즈가 주어지며 출력은 학습 데이터와 유사한 패턴으로 변화하는 함수를 학습
  - 인공신경망의 장단점
    - 장점
      - 비선형적 예측 가능
      - 다양한 데이터를 유형, 새로운 학습 환경, 불완전한 데이터 입력 등 적용가능
    - 단점
      - 데이터가 커질수록 학습시키는 데에 시간 비용이 기하급수적으로 커질 수 있다.

#### 서포트벡터머신

- SVM의 주요 요소
  - 벡터
  - 결정역역
  - 초평면
  - 서포트벡터
  - 마진
- SVM의 핵심적 특징
  - 여백(마진)의 최대화로 일반화 능력의 극대화
  - 초평면의 마진은 각 서포트 벡터를 지나는 초평면 사이의 거리를 의미
- 장단점
  - 장점
    - 다양한 라이브러리로 사용하기 쉬우며 분류, 회귀 예측 문제에 동시에 활용 가능
    - 신경망 기법에 비해 적은 데이터로 학습이 간으하며 과대적합, 과소적합 정도가 덜하다
  - 단점
    - 이진분류만 가능하며 데이터가 많은 시 모델 학습 시간이 오래 소요도니다
    - 가각 분류에 대한 모델 구축이 필요하다

#### 연관성분석

- 연관성분석
  - 둘 이상의 거래, 사전에 포함된 항목들의 관련성을 파악하는 탐색적 데이터 분석 기법
- 순서
  - 데이터 간 규칙 생성
  - 어떠한 규칙이 데이터에 특성에 부합되는지 기준 설정
    - 지지도
    - 신뢰도
    - 향상도
  - 규칙의 효용성 평가
- 아프리오리 알고리즘
- 연관성분석의 장단점
  - 장점 : 분석 결과가 이해하기 쉽고 실제 적용하기에 용이하다
  - 단점
    - 품목이 많아질수록 연관성 규칙이 더 많이 발견되나 의미성에 대해 사전 판단이 필요
    - 상당 수의 계산 과정이 필요

#### 군집분석

- 군집분류 시 기본적인 가정
  - 하나의 군집 내에 속한 개체들의 특징은 동일하다
- 군집분석의 척도
  - 거리는 값이 작을수록 두 관찰치가 유사함
  - 유사성은 값이 클수록 두 관찰치가 서로 유사함
  - 거리
    - 유클리드 거리
    - 맨허탄 거리 : 블록별로 택시가 지나가 듯이 출발점과 도착점을 잇는 가장 짧은 거리
    - 민코우스키 거리 : m=1일 때 맨하탄 거리와 같고 m=2 일때 유클리드 거리와 같다.
    - 마할라노비스 거리
    - 자카드 거리 : 비교 대상인 두 개의 객체를 특징즐의 결헙으로 간주하여 범주형 데이터에서 비유사성을 측정하는 지표
- 군집분석의 종류
  - 계층적 군집분석
    - 최단 연결법
    - 최장 연결법
    - Ward 연결법
  - 비계층적 군집분석
    - K-평균
    - 밀도비간 클러스터링 (DBSCAN)
    - 확률 분포 기반 클러스터링
- 군집분포의 장단점
  - 장점
    - 다양한 데이터 형태에 적용이 가능하다
    - 특징 변수에 대한 정의가 필요하지 않는 적용이 용이한 탐색적 기법이다
  - 단점
    - 초기 군집 수, 관측시간의 거리 등의 결정에 따라 결과가 바뀔 수 있다
    - 사전 주어진 목표가 없으므로 결과 해석이 어렵다.
